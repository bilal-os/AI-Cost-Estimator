import json
from groq import Groq

class FunctionPointAnalyzer:
    def __init__(self, api_key, vaf=1.14):
        """
        Initialize Groq client for Function Point Analysis
        
        :param api_key: Groq API key
        """
        self.client = Groq(api_key=api_key)
        self.vaf = vaf  # Fixed VAF for calculation
        # Language Productivity Factors (LOC/FP)
        self.language_productivity = {
            "Assembly": 320,
            "C": 128,
            "C++": 64,
            "Java": 48,
            "Python": 15,
            "Visual Basic": 20,
            "SQL": 12
        }

    def analyze_requirements(self, extracted_text):
        """
        Analyze requirements document using Groq API for Function Point Analysis
        
        :param extracted_text: Text extracted from requirements document
        :return: Structured FPA analysis as dictionary
        """
        try:
            # System prompt for FPA analysis
            system_prompt = """You are a precise requirements document analysis tool specializing in Function Point Analysis (FPA) metrics. Your task is to meticulously extract and categorize requirements using standardized definitions:
            Metric Definitions:
            - External Inputs (EI): Data or control inputs from outside the system boundary that require processing. Includes user-submitted forms, data entry screens, configuration updates, and file uploads that fundamentally transform or update system state.
            - External Outputs (EO): Processed data or control information generated by the system and sent to external users or systems. Encompasses reports, notifications, exported files, API responses, and calculated results that provide value beyond simple data retrieval.
            - External Inquiries (EQ): Immediate, real-time data retrievals that involve minimal processing. Characterized by direct lookups, search operations, status checks, or read-only interactions that return existing information without significant computational complexity.
            - Internal Logical Files (ILF): Persistent data collections maintained and managed within the system's boundary. Includes database tables, configuration repositories, user profile stores, transaction logs, and any structured data maintained exclusively by the system.
            - External Interface Files (EIF): Data references or files originated and maintained by external systems but referenced or used by the current system. Examples include shared reference databases, third-party API data sources, standardized data exchanges, or read-only external repositories.
            Analysis Protocol:
            1. Systematically scan entire requirements document
            2. Identify unique metric instances with precise context from the requirements document
            3. Quantify occurrences rigorously
            4. Provide concrete, module-specific examples, only give their names no explanation.
            5. Generate structured JSON output:
            {
              "EI": {
                "count": 0,
                "examples": [
                ]
              },
              "EO": {
                "count": 0,
                "examples": []
              },
              "EQ": {
                "count": 0,
                "examples": []
              },
              "ILF": {
                "count": 0,
                "examples": []
              },
              "EIF": {
                "count": 0,
                "examples": []
              }
            }
            Output Requirements:
            - Zero interpretative text
            - Strictly structured JSON response
            """
            
            # Create chat completion request
            response = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": system_prompt
                    },
                    {
                        "role": "user",
                        "content": f"Analyze the following requirements document for Function Point Analysis:\n\n{extracted_text}"
                    }
                ],
                model="llama-3.2-3b-preview",
                response_format={"type": "json_object"}
            )
            
            # Parse the JSON response
            fpa_analysis = json.loads(response.choices[0].message.content)
            return fpa_analysis
        
        except Exception as e:
            print(f"Error in FPA analysis: {str(e)}")
            # Return a default structure if analysis fails
            return {
                "EI": {"count": 0, "examples": []},
                "EO": {"count": 0, "examples": []},
                "EQ": {"count": 0, "examples": []},
                "ILF": {"count": 0, "examples": []},
                "EIF": {"count": 0, "examples": []}
            }

    def calculate_project_metrics(self, fpa_analysis, language="Java"):
        """
        Calculate project metrics based on Function Point Analysis
        
        :param fpa_analysis: Dictionary containing FPA results
        :param language: Programming language to use for LOC/FP (default is Java)
        :return: Dictionary with project estimation metrics
        """
        # Calculate unadjusted function points
        total_function_points = (
            fpa_analysis['EI']['count'] * 4 +
            fpa_analysis['EO']['count'] * 5 +
            fpa_analysis['EQ']['count'] * 3 +
            fpa_analysis['ILF']['count'] * 10 +
            fpa_analysis['EIF']['count'] * 7
        )

        # Apply Value Adjustment Factor (VAF)
        adjusted_function_points = total_function_points * self.vaf

        # Select LOC/FP for the chosen language
        loc_per_fp = self.language_productivity.get(language, 48)  # Default to Java if not found

        # Calculate estimated KLOC
        estimated_loc = adjusted_function_points * loc_per_fp
        estimated_kloc = estimated_loc / 1000

        return {
            "totalFunctionPoints": total_function_points,
            "projectSize": estimated_kloc,
            "developmentEffort": 0,
            "effortMultiplier": 0,
            "developmentTime": 0,
            "estimatedKLOC": estimated_kloc
        }